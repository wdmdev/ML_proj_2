\subsection{Variables and Data Transformations}
\respdist{0}{40}{60}
We are interested in a multi-class classification problem: Classifying the municipalities into three different risk categories depending on the reported thefts/burglaries in the \textbf{RT} feature. 
Specifically we want to classify municipalities based on three intervals for \textbf{RT}: \textit{Low}, \textit{Medium}, and \textit{High}.
\\
The minimum \textbf{RT} value is 3 reported thefts/burglaries per 1000 inhabitants, the max is 141 and the mean is 48. Three risk groups are made by splitting the max of 141 incidents into three equally sized intervals. The table below shows the categories, their corresponding approximate \textbf{RT} interval, and the standardized values of the intervals.

\begin{table}[H]
	\centering
	\begin{tabular}{|l|c|c|}
		\hline
		\textbf{Risk Category}	&	\textbf{RT Interval}	&\textbf{Standardized RT Interval} 	\\
		Low					&	$[0, 47]$			&	$[-2.2, 0.07]$	\\
		Medium				&	$]47, 94]$			&	$]0.07, 2.3]$	\\
		High				&	$]94, 141]$			&	$]2.3, 4.6]$ \\
		\hline
	\end{tabular}
	\caption{Table of Risk Category and corresponding \textbf{RT} intervals}
	\label{riskCat}
\end{table}
\noindent
The standardized values of the categories are used as the interval boundaries in the code.
The reason why the standardized category \textit{Low} can be negative is, that the mean is subtracted from the values.
This is a very simplistic definition for risk scoring a municipality, but it suffices, as this report is merely an example of how classification could be done.
\\\\
As in the linear regression example the same data transformations has been performed for missing values, and standardization of the features. 
Besides these transformations a new nominal feature, \textit{Risk Category} (\textbf{RC}), has been added. 
The \textbf{RC} feature is of type string with values \textit{low}, \textit{medium}, and \textit{high}. 
It has been calculated based on which standardized interval(Table \ref{riskCat}) the \textbf{RT} value falls within. The transformation yielded 24 y-values of \textit{high}, 473 of \textit{medium}, and 679 of \textit{low} risk.

\subsection{Models}
\respdist{0}{40}{60}
Again three different models are tested. The test seed is set to 30 to ensure the same splits for all models in the two-level cross validation.

\paragraph{Baseline}
The baseline model was made to just predict the input to be in the category which occurs the most in the training split. This made sure, that the prediction did not depend on any features in the data set. Thus, by comparing the other models with the baseline, it was possible to see if training on the features even helped improve the classification performance at all.

\paragraph{Logictic Regression}
The logistic regression model is regularized through a regularization constant $\lambda$ in the interval $[10^{-3},10^{2}]$. The model itself builds on similar principles as for linear regression, but differs in that it outputs probabilities for the input belonging to a specific class. These probabilities are used with thresholding to translate them into class labels. The chosen class is the class matching the index with the highest probability from the logistic regression model.

\paragraph{Decision Tree Classifier}
A decision tree classifier is used for the \textit{Method 2} model. The controlling parameter is the \textit{minimum impurity decrease}(\textbf{mid}) parameter. The parameter decides if a node in the tree will be split. The split happens if the split induces a reduction of the impurity greater than or equal to the controlling \textbf{mid} parameter e.g. if \textbf{mid} is $10^{1.3}$ and the potential impurity reduction from a split is $10^{1.5}$ then the split happens.

\subsection{Two-level Cross Validation}
\respdist{20}{10}{70}
Again two level cross validation was performed on the three models as with linear regression. The result of the cross validation can be seen in the table below.
\begin{table}[H]
		\centering
	\begin{tabular}{lrrrrr}
		\jl{Outer fold}	& \multicolumn{2}{c}{Logistic Regression}	& \multicolumn{2}{c}{Decision Tree}	& Baseline	\\
		\jl i&\jl{$ h_i^* $}	&\jl{$ E_i^{\text{test}} $}	&\jl{$ \lambda_i^* $}	&\jl{$ E_i^{\text{test}} $}	&\jl{$ E_i^{\text{test}} $}	\\\hline
        1 & 2.33 &  0.09 &       0.00 &     0.18 &         0.36 \\
		2 & 1.84 &  0.00 &       0.00 &     0.18 &         0.64 \\
		3 & 1.84 &  0.09 &       0.00 &     0.09 &         0.18 \\
		4 & 1.84 &  0.18 &       0.00 &     0.18 &         0.36 \\
		5 & 2.33 &  0.27 &       0.00 &     0.18 &         0.64 \\
		6 & 0.11 &  0.18 &       0.01 &     0.09 &         0.27 \\
		7 & 62.51 & 0.00 &       0.00 &     0.30 &         0.50 \\
		8 & 49.42 & 0.20 &       0.01 &     0.30 &         0.60 \\
		9 & 100.00 & 0.10 &       0.00 &     0.10 &         0.40 \\
		10& 100.00 & 0.00 &       0.00 &     0.20 &         0.20 \\
		\hline
		\jl{$ \hat E^{\text{gen}} $}  & & 0.0102 & &0.0162 & 0.0374
	\end{tabular}
\end{table}
\noindent
Looking at the results, it shows the logistic regression model and the decision tree classifier performs with a lower generalization error than the baseline model. This is what we hoped for, as it points to the conclusion, that training on the features in the data set actually does make sense. 
\\
Though, to compare the models and choose a best fit for the problem, we still need a final step, which includes statistical evaluation using the McNemar test.

\subsubsection{Statistical Comparision of the Three Models - McNemar Test}
\respdist{30}{30}{40}
The difference in accuracy between two compared models, was estimated using the formula.
	\begin{equation}
	\hat{\theta} = \frac{n_{12}-n_{21}}{n}
	\label{logi:eq:theta}
	\end{equation}
This was done between the logistic regression model and decision tree classifier and the logistic regression model and baseline model.
Based on the difference a $p$ and $q$ value was calculated and used to create a 95\% confidence interval(CI) for the two differences in accuracy, based on the following equations.
\begin{equation}
\begin{array}{l}{\theta_{L}=2 \operatorname{cdf}_{B}^{-1}\left(\frac{\alpha}{2} | \alpha=p, \beta=q\right)-1} \\ {\theta_{U}=2 \operatorname{cdf}_{B}^{-1}\left(1-\frac{\alpha}{2} | \alpha=p, \beta=q\right)-1}\end{array}
\label{logi:eq:conf}
\end{equation}
Where $\theta_{L}$ is the lower bound and $\theta_{U}$ is the upper bound of the CI.
\\
Finally, the p-value for testing the $H_{0}$-hypothesis, that the two compared models have the same performance in accuracy, was calculated using the formula.
\begin{equation}
p=2 \mathrm{cdf}_{\mathrm{binom}}\left(m=\min \left\{n_{12}, n_{21}\right\} | \theta=\frac{1}{2}, N=n_{12}+n_{21}\right)
\label{logi:eq:p}
\end{equation}
\\
The results from equations (\ref{logi:eq:theta}), (\ref{logi:eq:conf}), and (\ref{logi:eq:p}) can be seen in table \ref{tab:logi_McNemar} below

\begin{table}[H]
	\centering
	\begin{tabular}{l r r l}
		&Logistic Reg. and Decision Tree	&Logistic Reg. and BL&Decision Tree and BL	\\\hline
		$ \hat{\theta} $	& $6.6038\ctp{-2}$	& $3.0189\ctp{-1}$	&$2.3585\ctp{-1}$\\
		$ \theta_{L} $		&$ 6.2998\ctp{-2}$ 	& $2.9893\ctp{-1}$	&$ 2.3255\ctp{-1}$\\
		$ \theta_{U} $		&$ 6.9300\ctp{-2}$  & $3.0643\ctp{-1}$	&$ 2.4048\ctp{-1} $\\
		$ p $ 				&$ 0.2649 $  		&$5.1614\ctp{-6} $	&$6.2104\ctp{-4} $
	\end{tabular}
	\caption{Statistical comparison of the three different classification models.}\label{tab:logi_McNemar}
\end{table}\noindent
For both the logistic regression model and the decision tree classifier as compared to the baseline model, we see that they have a $p$-value significantly smaller than $0.05$ which is evidence supporting that the models are better than the baseline in categorizing the data.
\\
Looking at the two models logistic regression, and the decision tree the $p$-value is greater than $0.05$. This supports the null hypothesis, that there is no significant difference in the performance of the two classification models on the data set. For a conclusion from the current results it seems either logistic regression or a decision tree classifier could be viable options for risk categorizing the municipalities. But, to get a better foundation for choosing a model, further studies should be carried out. These studies could for instance investigating other controlling parameters and intervals for said parameters.
\\
As a test a final logistic regression model was trained on the entire data set using the controlling parameter $\lambda = 1.84$. Then by looking at the coefficients of the model they showed, that the following features had a coefficient of 0, meaning no weight in the classification: \textit{half year service expenses per inhabitant until 2017}, \textit{total region and primary payment percentages}, and \textit{expenses to administration per inhabitant}. For further studies the classifications could tried without these features.

\clearpage